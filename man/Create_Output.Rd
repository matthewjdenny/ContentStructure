% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/Create_Output.R
\name{Create_Output}
\alias{Create_Output}
\title{A Function to generate diagnostic plots and interpretable output for a list of 1 to N model output objects from running the ContentStructure model.}
\usage{
Create_Output(data_name, only_generate_summaries = T, data_directory,
  print_agg_stats = T, using_county_email_data = F,
  Topic_Model_Burnin = 50, Skip = 0, Thin = 1, Used_MP = F,
  MP_Name = "Gender", data_list = NULL, Auth_Attr = NULL,
  Vocabulary = NULL, load_results_from_file = F,
  Estimation_Results = NULL, save_results = F)
}
\arguments{
\item{data_name}{The name of organization data file as in the function to run the model.}

\item{only_generate_summaries}{If TRUE, then only generate a one-page-per-cluster pdf summary of model output for each county, otherwise generate a ton of output.}

\item{data_directory}{The directory where all .Rdata files are stored -- also where all output will be stored.}

\item{print_agg_stats}{If TRUE, generates a plot comapring topics frequency across all clusters and a trace plot of th topic model log likelihood -- very useful.}

\item{using_county_email_data}{Logical if you are using North Carolina County Government email data that are properly formatted to produce aggregate level output.}

\item{Topic_Model_Burnin}{The number of iterations of Gibbs sampling that should be discarded before calculated Geweke statistic to determine model convergence. You will simply want to set it pretty low and then look at the trace to determine where you should set it to provide evidence of convergence.}

\item{Skip}{The number of MH for LSM iterations to skip when generating out (if your burnin was not long enough).}

\item{Thin}{The number of iterations to skip in the MH for LSM chain when generating output. Set to 1 as default does not thin but can be set higher to make plotting easier if you took a lot of samples.}

\item{Used_MP}{If TRUE then will generate output for mixing parameter estimates (if they were used).}

\item{MP_Name}{If we are using mixing parameters then specify the name of the binary variable for which mixing parameter estimates were created in the author_attributes dataset.}

\item{data_list}{A vector containing the names of organization data files as in the function to run the model. Should only contain names of those organizations for which output has already been created. Only for use with county government datasets (not for public use)}

\item{Auth_Attr}{The author attributes dataframe.}

\item{Vocabulary}{The vocabulary dataframe.}
}
\value{
A list object with 4 entries and the following structure: Cluster_Data contains cluster level data including top words and mixing parameters (with standard errors) if applicable. Actor_Data contains actors level data (all of the Auth_Attr dataframe) plus average latent positions for each actor in each dimension (2 currently), for each cluster. Token_Data contains the counts of each token for each topic, along with the edge counts for that topic and the cluster assignment for it. Vocabulary simply holds the vocabulary as a vector for easy handling.
}
\description{
A Function to generate diagnostic plots and interpretable output for a list of 1 to N model output objects from running the ContentStructure model.
}

